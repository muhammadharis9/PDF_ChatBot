# PDF_ChatBot (DocuMind AI) â€” Chat with PDFs using RAG

DocuMind AI is a **PDF Question-Answering / Summarization** chatbot built with a **Retrieval-Augmented Generation (RAG)** pipeline.  
You upload a PDF, the app chunks + embeds it into a **ChromaDB** vector store, and then you can ask questions (or request a summary) powered by **LangChain + Google Gemini**.

![Alt text](images/document.png)

---

## âœ¨ What this project does

- **PDF ingestion** using `PyPDFLoader`
- **Chunking** via `RecursiveCharacterTextSplitter`
- **Embeddings** using `sentence-transformers/all-MiniLM-L6-v2` (Hugging Face)
- **Vector database** with **ChromaDB** (persistent store)
- **RAG Q/A** using **LangChain RetrievalQA** + **Gemini (ChatGoogleGenerativeAI)**
- **API backend** with **FastAPI**
- **Experiment-first workflow** (notebook â†’ modular code)

### About â€œSummarizationâ€
There isnâ€™t a dedicated `/summarize` endpoint yet, but you can ask:
- â€œSummarize this documentâ€
- â€œGive me a 10-bullet summaryâ€
- â€œSummarize page 1 / the section about Xâ€

Since the chatbot answers using retrieved context, it behaves like â€œsummary-from-retrieved-chunksâ€.

### About â€œOCRâ€
OCR for scanned PDFs is **not implemented yet**. Itâ€™s included in the roadmap below.

---

## ğŸ§  Architecture (high level)

1. **Experimentation (Notebook)**  
   Prototype the full logic end-to-end in `research/experiment.ipynb`.

2. **Modular RAG Core (`src/`)**  
   - `src/helper.py` â†’ loading, splitting, embeddings/vectorstore
   - `src/pipeline.py` â†’ retrieval + prompting + LLM chain

3. **Backend API (`backend/`)**
   - `backend/app.py` exposes:
     - `POST /upload` â†’ process PDF and build vector store
     - `POST /chat` â†’ ask questions on the uploaded PDF

4. **Frontend (planned / UI concept)**
   - The screenshot represents the intended UI flow (upload + chat).
   - You can connect any frontend (HTML/React/Streamlit) to the FastAPI endpoints.

---

## ğŸ“ Project Structure

```bash
PDF_ChatBot/
â”œâ”€â”€ backend/
â”‚   â””â”€â”€ app.py                  # FastAPI backend (upload + chat endpoints)
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ helper.py               # PDF loader, chunking, embeddings, Chroma store
â”‚   â””â”€â”€ pipeline.py             # RetrievalQA chain (Gemini + LangChain)
â”œâ”€â”€ research/
â”‚   â””â”€â”€ experiment.ipynb        # Experimentation notebook (prototype â†’ modularize)
â”œâ”€â”€ chroma_langchain_db/        # (local) persisted vector store
â”œâ”€â”€ pyproject.toml              # Dependencies (uv-based project)
â”œâ”€â”€ template.sh                 # Initial scaffolding script (template approach)
â””â”€â”€ README.md
