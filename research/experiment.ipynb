{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ed59edc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\PDF_ChatBot\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "faebecbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"E:/CV.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = PyPDFLoader(file_path=file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a56aa84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "load = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86f8fa01",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 100,\n",
    "    chunk_overlap= 20\n",
    ")\n",
    "\n",
    "splitted_text = text_splitter.split_documents(load)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f7eb0f48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'producer': 'pdfTeX-1.40.27', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-11-15T23:15:52+00:00', 'author': '', 'keywords': '', 'moddate': '2025-11-15T23:15:52+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.27 (TeX Live 2025) kpathsea version 6.4.1', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'E:/CV.pdf', 'total_pages': 2, 'page': 0, 'page_label': '1'}, page_content='Muhammad Haris Imtiaz')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splitted_text[:1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a6e2500",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "907e0a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model = \"sentence-transformers/all-MiniLM-L6-v2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d84b7e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed = HuggingFaceEmbeddings(model=embedding_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1f94a558",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_embed = Chroma.from_documents(\n",
    "    documents=splitted_text,\n",
    "    embedding=embed,\n",
    "    collection_name=\"pdfs\",\n",
    "    persist_directory=\"E:/PDF_ChatBot/chroma_langchain_db\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "143585b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "584"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(final_embed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "53b251f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection = final_embed._collection\n",
    "results = collection.get(include=[\"embeddings\", \"documents\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3c3dc3c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "584"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(results['documents'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5752e9c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['ids', 'embeddings', 'documents', 'uris', 'included', 'data', 'metadatas'])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58dda48a",
   "metadata": {},
   "source": [
    "#### Now the Functions will be made for the later use  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0e632c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pdf(file_path):\n",
    "    loader = PyPDFLoader(file_path=file_path)\n",
    "    load = loader.load()\n",
    "\n",
    "    return load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0aac65e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitting(load):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 100,\n",
    "    chunk_overlap= 20)\n",
    "\n",
    "    splitted_text = text_splitter.split_documents(load)\n",
    "\n",
    "    return splitted_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e4ef4757",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embeds(load):\n",
    "    embedding_model = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "    embed = HuggingFaceEmbeddings(model=embedding_model)\n",
    "    \n",
    "    final_embed = Chroma.from_documents(\n",
    "    documents=splitted_text,\n",
    "    embedding=embed,\n",
    "    collection_name=\"pdfs\",\n",
    "    persist_directory=\"E:/PDF_ChatBot/chroma_langchain_db\"\n",
    ")\n",
    "    return final_embed\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_embeds(load):\n",
    "    embedding_model1 = input(\"Please provide the model for embedding which you want to load: \")\n",
    "    embedding_model = embedding_model1\n",
    "    embed = HuggingFaceEmbeddings(model=embedding_model)\n",
    "    \n",
    "    final_embed = Chroma.from_documents(\n",
    "    documents=splitted_text,\n",
    "    embedding=embed,\n",
    "    collection_name=\"pdfs\",\n",
    "    persist_directory=\"E:/PDF_ChatBot/chroma_langchain_db\"\n",
    ")\n",
    "    return final_embed\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6100e157",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import streamlit as st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eac990b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f4610337",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.getenv(\"GOOGLE_API_KEY\"):\n",
    "    st.error(\"Err\")\n",
    "    st.stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b5484849",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_classic.chains import RetrievalQA\n",
    "from langchain_core.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "01d5e5bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting up the brain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd23f62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f3d1b9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    temperature=1, \n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    #google_api_key = \"AIzaSyB1Gm74LHNB9kT2tnI4xyay1Pc1iqB_lk4\",\n",
    "    max_retries=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9f58483b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d789593b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ret = final_embed.as_retriever(search_kwargs = {\"k\" : 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cb7abdb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(tags=['Chroma', 'HuggingFaceEmbeddings'], vectorstore=<langchain_community.vectorstores.chroma.Chroma object at 0x0000018C049C8A50>, search_kwargs={'k': 2})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d0a19f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#connecting the brain and retrival for the responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0789c46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "You are an expert and professional in reading PDFs. Your task is to answer questions based ONLY on the following context provided from a PDF document.\n",
    "\n",
    "Guidelines:\n",
    "1. Suggest him about job portals as well.\n",
    "2. Keep your answer clear, structured, and easy to read.\n",
    "3. Use bullet points if listing multiple items.\n",
    "4. Do not make up information.\n",
    "5. You can also search information from internet and give him suggestion\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\n",
    "Helpful Answer:\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4369ac51",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_prompt = PromptTemplate(\n",
    "    template=template,\n",
    "    input_variables= [\"context\" , \"question\"]\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3ee648c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm = llm,\n",
    "    chain_type = \"stuff\",\n",
    "    retriever = ret,\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs = {\"prompt\" : my_prompt}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cf95d08a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = qa_chain.invoke({\"query\" : \"summarize it and suggest him what type of job he needs to apply \"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6d3152c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the context provided:\n",
      "\n",
      "The individual is currently serving as a **GenAI Intern**, a role they started in September 2025 and is ongoing.\n",
      "\n",
      "Given this experience, the individual should focus on applying for roles that leverage their Generative AI and broader AI/Machine Learning skills.\n",
      "\n",
      "**Suggested Job Types to Apply For:**\n",
      "\n",
      "*   **Entry-Level / Junior Generative AI Engineer/Developer:** Roles specifically focused on developing, deploying, and maintaining Generative AI models and applications.\n",
      "*   **Junior Machine Learning Engineer:** Positions involving the broader application of machine learning principles, model training, and data pipeline development.\n",
      "*   **AI/ML Research Assistant:** If interested in further research and development within academic or corporate labs.\n",
      "*   **Data Scientist (with AI/ML focus):** Roles that combine data analysis with the implementation of AI and machine learning solutions.\n",
      "*   **AI Prompt Engineer:** Specializing in designing and optimizing prompts for various AI models to achieve desired outputs.\n",
      "*   **AI Product Intern/Associate:** If there's an interest in the product development and strategy side of AI solutions.\n",
      "\n",
      "**Job Portals to Consider:**\n",
      "\n",
      "*   **General Professional Networks:**\n",
      "    *   **LinkedIn Jobs:** Excellent for professional networking and discovering a wide range of AI/ML positions.\n",
      "    *   **Indeed:** One of the largest job aggregators with numerous tech and AI-related postings.\n",
      "    *   **Glassdoor:** Provides job listings, company reviews, and salary information.\n",
      "    *   **ZipRecruiter:** Features a broad database of job openings across various industries.\n",
      "*   **Tech-Specific Job Boards:**\n",
      "    *   **Hired.com:** Focuses on tech roles and often connects candidates with companies directly.\n",
      "    *   **AngelList Talent:** Ideal for finding opportunities at startups, many of which are in the AI space.\n",
      "    *   **Kaggle Jobs:** Often lists data science and machine learning-specific roles.\n",
      "    *   **Built In [Your City/Region]:** (e.g., Built In NYC, Built In San Francisco) â€“ Useful for finding local tech and AI jobs within specific ecosystems.\n",
      "*   **Company Career Pages:**\n",
      "    *   Directly check the career pages of companies known for their work in AI, machine learning, and Generative AI (e.g., Google, Microsoft, NVIDIA, OpenAI, Anthropic, Hugging Face, etc.).\n",
      "*   **University Career Services:** If still affiliated with an academic institution, their career services often have exclusive job postings and networking events.\n"
     ]
    }
   ],
   "source": [
    "print(x[\"result\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a5eba1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pdf-chatbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
